{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparameter optimization\n",
    "\n",
    "After hipothesis testing, we will optimize the hyperparameters of:\n",
    "\n",
    "1. Neural Network\n",
    "2. XGBoost\n",
    "3. Random Forest\n",
    "\n",
    "We will use RandomizedSearch to determine some hyperparameters and Genetic Algorithm to determine the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn_genetic.space import Continuous, Categorical, Integer\n",
    "from sklearn_genetic.plots import plot_fitness_evolution, plot_search_space\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette(\"Set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../Models/ParametrizationData/parametrization.pkl\"\n",
    "X_train, X_test, y_train, y_test = pickle.load(open(filename, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearch\n",
    "\n",
    "Here, we will make a first optimization of the hyperparameters of the models using RandomizedSearch. This will be a general approach and will help us to have a better idea of the hyperparameters that we should focus on later, when we use the Genetic Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_param_grid = {\n",
    "    \"hidden_layer_sizes\": [(25,), (50,), (25, 25), (50, 50)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"solver\": [\"adam\", \"sgd\"],\n",
    "    \"alpha\": [0.001, 0.01],\n",
    "    \"learning_rate\": [\"adaptive\"],\n",
    "    \"max_iter\": [500, 1000],\n",
    "}\n",
    "\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"subsample\": [0.7, 0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 0.9],\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [5, 10, 20],\n",
    "    \"min_samples_split\": [3, 5, 7],\n",
    "    \"min_samples_leaf\": [2],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters for MLPClassifier: {'solver': 'adam', 'max_iter': 1000, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 50), 'alpha': 0.001, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp_grid_search = RandomizedSearchCV(\n",
    "    mlp, mlp_param_grid, cv=3, scoring=\"accuracy\", verbose=2, n_jobs=-1\n",
    ")\n",
    "mlp_grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters for MLPClassifier:\", mlp_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters for XGBoostClassifier: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.2, 'colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=42)\n",
    "xgb_grid_search = RandomizedSearchCV(\n",
    "    xgb, xgb_param_grid, cv=3, scoring=\"accuracy\", verbose=2, n_jobs=-1\n",
    ")\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters for XGBoostClassifier:\", xgb_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juanj\\OneDrive - UPB\\Estructurados\\Final\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "3 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juanj\\OneDrive - UPB\\Estructurados\\Final\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\juanj\\OneDrive - UPB\\Estructurados\\Final\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\juanj\\OneDrive - UPB\\Estructurados\\Final\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\juanj\\OneDrive - UPB\\Estructurados\\Final\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\juanj\\OneDrive - UPB\\Estructurados\\Final\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.96283757 0.85522641 0.86571797 0.96458043 0.86030822 0.86895697\n",
      "        nan 0.985195   0.96415565 0.98492638]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MLPClassifier: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_grid_search = RandomizedSearchCV(\n",
    "    rf, rf_param_grid, cv=3, scoring=\"accuracy\", verbose=2, n_jobs=-1\n",
    ")\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters for RandomForest:\", rf_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm\n",
    "\n",
    "Here we will make a more throrough optimization of the hyperparameters of the models using the Genetic Algorithm. This will be a more specific approach and will take into account the hyperparameters that we found to be more important in the RandomizedSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam, adaptive, relu\n",
    "\n",
    "mlp_param_grid = {\n",
    "    \"hidden_layer_sizes\": [(25,), (50,), (25, 25), (50, 50)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"solver\": [\"adam\", \"sgd\"],\n",
    "    \"alpha\": [0.001, 0.01],\n",
    "    \"learning_rate\": [\"adaptive\"],\n",
    "    \"max_iter\": [500, 1000],\n",
    "}\n",
    "\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"subsample\": [0.7, 0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 0.9],\n",
    "}\n",
    "\n",
    "# sqrt\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [5, 10, 20],\n",
    "    \"min_samples_split\": [3, 5, 7],\n",
    "    \"min_samples_leaf\": [2],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparametrization results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
