{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation and Sampling\n",
    "\n",
    "Throughout this notebook, we will transform categorical data into numerical data and scale numerical data for the training set. We will use the following techniques:\n",
    "\n",
    "- MinMaxScaler for numerical data\n",
    "- LabelEncoder for class\n",
    "- Dummy creation for categorical data\n",
    "\n",
    "We will sample the data to work with a smaller dataset.\n",
    "\n",
    "We will save the transformed data into [Data/WorkingData](https://github.com/faendal/MushroomEdibilityPrediction/tree/main/Data/WorkingData) folder.\n",
    "\n",
    "Finally, we will save the transformation objects into [Models/Transformations](https://github.com/faendal/MushroomEdibilityPrediction/tree/main/Models/Transformations) folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/FullyClean/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1818187 entries, 0 to 1818186\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Dtype   \n",
      "---  ------           -----   \n",
      " 0   class            category\n",
      " 1   cap-surface      category\n",
      " 2   cap-color        category\n",
      " 3   gill-attachment  category\n",
      " 4   gill-color       category\n",
      " 5   stem-height      float64 \n",
      " 6   stem-width       float64 \n",
      " 7   stem-color       category\n",
      "dtypes: category(6), float64(2)\n",
      "memory usage: 38.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Data type correction\n",
    "\n",
    "types = {\n",
    "    column: \"category\"\n",
    "    for column in df.columns\n",
    "    if df[column].dtype == \"object\"\n",
    "}\n",
    "df = df.astype(types)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "\n",
    "df[[\"stem-height\", \"stem-width\"]] = minmax.fit_transform(df[[\"stem-height\", \"stem-width\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "labelEncoder = LabelEncoder()\n",
    "\n",
    "df[\"class\"] = labelEncoder.fit_transform(df[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap-surface: 11\n",
      "cap-color: 8\n",
      "gill-attachment: 6\n",
      "gill-color: 7\n",
      "stem-color: 7\n"
     ]
    }
   ],
   "source": [
    "categorical = df.select_dtypes(include=\"category\").columns\n",
    "\n",
    "for column in categorical:\n",
    "    unique = df[column].nunique()\n",
    "    print(f\"{column}: {unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=categorical, drop_first=False, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sampling\n",
    "\n",
    "We currently have over 1.8 Million rows and 57 colums. This is a lot of data to work with. We will sample the data to reduce the size of the dataset and save it into the directory mentioned before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420000, 42)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[\"class\"])\n",
    "y = df[\"class\"]\n",
    "\n",
    "# Sampling\n",
    "X_sampled, _x, y_sampled, _y = train_test_split(X, y, test_size=0.7690006, stratify=y)\n",
    "\n",
    "# DataFrame creation from sampled data\n",
    "df_sampled = X_sampled.copy()\n",
    "df_sampled[\"class\"] = y_sampled\n",
    "print(df_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled.to_csv(\"../Data/WorkingData/train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../Models/Transformations/transformations.pkl\"\n",
    "variables = X.columns._values\n",
    "pickle.dump([minmax, labelEncoder], open(filename, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
