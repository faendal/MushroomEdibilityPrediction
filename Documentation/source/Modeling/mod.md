## Model Selection
- Experiment with various classification algorithms:
    - Classification Tree
    - Logistic Regression
    - K Nearest Neighbors (KNN)
    - Neural Network
    - XGBost
    - Random Forest
    - Gradient Boosting

## Model Training
- Train and evaluate each model
- Use hypothesis testing to determine the best 3 models
- Perform hyperparameter tuning with GridSearch and BayesSearch for the best model 3 models.
- Save the best model for each of the 6 algorithms chosen before.
- Save the best overall model for deployment.

This process was distributed into 3 notebooks:

1. **Model creation - Hypothesis testing**: [ModelCreation.ipynb](https://github.com/faendal/MushroomEdibilityPrediction/blob/main/Notebooks/2.1-ModelCreation.ipynb)

2. **Hyperparameter tuning**: [HiperparameterOptimization.ipynb](https://github.com/faendal/MushroomEdibilityPrediction/blob/main/Notebooks/2.2-HiperparameterOptimization.ipynb)

3. **Model Selection**: [ModelSelection.ipynb](https://github.com/faendal/MushroomEdibilityPrediction/blob/main/Notebooks/2.3-ModelSelection.ipynb)